import streamlit as st
from bokeh.models.widgets import Button
from bokeh.models import CustomJS
from streamlit_bokeh_events import streamlit_bokeh_events
import g4f

prompt = ""


def main():
    global prompt

    st.title("üí¨ Chatbot –±–æ—Ç –æ—Ç –ú–∏—Ö–∞–ª—ã—á–∞")
    st.caption("üöÄ –ß–∞—Ç –±–æ—Ç –≥–æ—Ç–æ–≤ –∫ –≤–∞—à–∏–º –∑–∞–ø—Ä–æ—Å–∞–º")

    recognition = st.toggle('–í—ã–∫–ª/–í–∫–ª –∑–∞–ø–∏—Å–∏ –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞')

    stt_button = Button(label="–ó–∞–ø–∏—Å—å —Å –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞", width=100, disabled=False, button_type="primary")
    stt_button.js_on_event("button_click", CustomJS(code="""
        var recognition = new webkitSpeechRecognition();
        recognition.continuous = true;
        recognition.interimResults = true;
    
        recognition.onresult = function (e) {
            var value = "";
            for (var i = e.resultIndex; i < e.results.length; ++i) {
                if (e.results[i].isFinal) {
                    value += e.results[i][0].transcript;
                }
            }
            if ( value != "") {
                document.dispatchEvent(new CustomEvent("GET_TEXT", {detail: value}));
            }
        }
        recognition.start();
        """))

    result = streamlit_bokeh_events(
        stt_button,
        events="GET_TEXT",
        key="listen",
        refresh_on_update=False,
        override_height=75,
        debounce_time=0)

    if result:
        if "GET_TEXT" in result:
            #st.write(result.get("GET_TEXT"))
            if recognition:
                prompt = result.get("GET_TEXT")
                print(prompt)
                st.session_state.messages.append({"role": "user", "content": prompt})
                with st.chat_message("user"):
                    st.write(prompt)
            






    # –•—Ä–∞–Ω–∏—Ç—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ LLM –æ—Ç–≤–µ—Ç—ã
    if "messages" not in st.session_state.keys():
        st.session_state.messages = [{"role": "assistant", "content": "–ü—Ä–∏–≤–µ—Ç! –Ø –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç, —Å–æ–∑–¥–∞–Ω–Ω—ã–π –¥–ª—è –ø–æ–º–æ—â–∏ –≤ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –∑–∞–¥–∞—á–∞—Ö. –Ø –º–æ–≥—É –æ—Ç–≤–µ—á–∞—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã, –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é, –ø–æ–º–æ–≥–∞—Ç—å –≤ –ø–æ–∏—Å–∫–µ —Ä–µ—à–µ–Ω–∏–π, –ø–µ—Ä–µ–≤–æ–¥–∏—Ç—å —Ç–µ–∫—Å—Ç—ã –Ω–∞ —Ä–∞–∑–Ω—ã–µ —è–∑—ã–∫–∏, —Å–æ–∑–¥–∞–≤–∞—Ç—å –Ω–∞–ø–æ–º–∏–Ω–∞–Ω–∏—è –∏ –º–Ω–æ–≥–æ–µ –¥—Ä—É–≥–æ–µ. –ï—Å–ª–∏ —É —Ç–µ–±—è –µ—Å—Ç—å –∫–∞–∫–∏–µ-–ª–∏–±–æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –≤–æ–ø—Ä–æ—Å—ã –∏–ª–∏ –∑–∞–¥–∞—á–∏, —è –ø–æ—Å—Ç–∞—Ä–∞—é—Å—å –ø–æ–º–æ—á—å!"}]


    # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏–ª–∏ —É–¥–∞–ª–µ–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏–π —á–∞—Ç–∞
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.write(message["content"])








    # Generate a new response if last message is not from assistant
    if st.session_state.messages[-1]["role"] != "assistant":
        with st.chat_message("assistant"):
            with st.spinner("Generating..."):
                print("Prompt: ", prompt)
                #st.chat_message("assistant").write("Generating...")
                response = g4f.ChatCompletion.create(
                    model="gpt-3.5-turbo",
                    messages=[{"role": "user", "content": f"{prompt}"}],
            )
                print("Response: ", response)

                placeholder = st.empty()
                full_response = ''
                for item in response:
                    full_response += item
                    placeholder.markdown(full_response)
                placeholder.markdown(full_response)
        message = {"role": "assistant", "content": full_response}
        st.session_state.messages.append(message)


    # User-provided prompt
    if prompt := st.chat_input():
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.write(prompt)


if __name__ == '__main__':
    main()